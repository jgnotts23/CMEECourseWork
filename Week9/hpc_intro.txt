##### Ecological Neutral Theory #####

Assumes all individuals are ecologically equivalent.

Misconceptions
- not the same as a null model
- does not assume all species are the same
- a model in which species are interchangeable is neutral

So what does it mean?
- The demographic properties of an individual are independent of its species diversity

Voter model (1975)
- purpose was to determine how people would vote
	- pick random neighbour (not far away)
	- you take their view or they take yours at random
	- Keep going for a while and see what happens
	- Patches of one colour formed (analagous to politics?)
- replace voting intention with a species and people with a habitat and this model can be applied to biology
- What we found
	- found some impenetrable clumps forming
	- there are edge effects
	- eventually everyone in each connceted group holds the same view
	- can introduce mutation (new colour) but likely to be outcompeted

Model rules in brief:
- In each timestep individuals die and are replaced with the offspring of another individual
- Sometimes a new species is dropped in instead of an offspring of an exisiting species
- Zero sum assumption is that an individual has to die for a new offspring to spawn, can be relaxed
- Speciation can be introduced through a single individual or several (i.e. migration) or through protracted speciation which is mutations within some organisms that survive and spread and form new species (i.e. more biological)
- spatial structure can be implemented by defining patch size (e.g. continent to island) or using dispersal kernel which uses a probability curve that dispersal will occur relative to the distance from the individual (less likely further away but still possible)

Applications in island biogeography
- MacArthur and Wilson's theory of island biogeography (1967) which factors in immigration and extinction


##### High Performance Computing (HPC) #####
- Embarassingly parallel problems
	- Graphics
	- Simulations with multiple parameters
	- Little to no communication between cpus
- Non-embarassingly parallel probelms
	- Fluid dynamics
	- A lot of the tasks run by a single program
	- Lots of communication between cpus

How do you parallelize your code?
- Use job numbers in code so they can be run simultaneously
- as.numeric(Sys.getenv("PBS_ARRAY_INDEX")) at top of code
- e.g.
	- for (i in 1:10){etc.    (one PC)
	OR
	- i <- as.numeric(Sys.getenv("PBS_ARRAY_INDEX")) at top of code   (HPC)
	- do_simulation(i)
- Important to specify random number seeds so simulations are identical

Handling memory
- Hard disk - slowest but biggest
- RAM - faster but smaller
- Cache - fastest but smallest

- Better to run tasks out of RAM than hard disk on HPC then write to hard disk at the end
- Output your code to a series of files (e.g. Output1.rda, Output2.rda, etc.)
- Good idea to include parameters used in each output (and random number seed)
- Write local code to read in series of output automatically
- Build a timer into your code
- Test your code locally to know your memory and time requirements
- On linux type 'top' to see how much memory a process is using

The practice of running code on a cluster
- cx1, a cluster of many ordinary computers, high-throughput (what I'll be using)
- cx2, massively parallel system, high-end
- ax4, large shared memory tasks, big data

- cx1.hpc.ic.ac.uk
- Login.cx1.hpc.ic.ac.uk
- Submit jobs to queue
- $HOME, data stored here, 1TB allocation
- ephemeral, for running larger jobs but only has 30 days lifetime
- $TMPDIR, temporary directory, don't lost code here, is also the working directory so code needs to be move back to $HOME



Coalescence
- Shared gene at a point in time between two individuals/species
- Advantages
	- always at equilibrium
	- much faster
	- sampling based
- Disadvantages
	- not ideal for time series
	- complex to program
	- fewer ways in which model can be changed
















